{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepL API for translating text\n",
    "\n",
    "This module requires a [DeepL API auth key](https://www.deepl.com/en/pro-api?utm_campaign=NL%7CSearch%7CC%7CBrand%7CEnglish&utm_term=deepl%20api&utm_source=adwords&utm_medium=ppc&hsa_acc=6985737809&hsa_cam=20950919016&hsa_grp=161811513510&hsa_ad=688253246151&hsa_src=g&hsa_tgt=kwd-900300572383&hsa_kw=deepl%20api&hsa_mt=e&hsa_net=adwords&hsa_ver=3&gad_source=1&gclid=CjwKCAjw3NyxBhBmEiwAyofDYbc4WasADHkofs86IVsfY8mP4a6CHKNHH88iEaOo87sCi79BNqxM8BoCGNkQAvD_BwE). Please make an auth key by signing up for DeepL API (free version should be enough) and paste your auth key in the third code section below. <br>\n",
    "See [DeepL API](https://www.deepl.com/docs-api/managing-glossaries/?utm_source=github&utm_medium=github-python-readme) for details.\n",
    "\n",
    "Click [here](https://www.deepl.com/docs-api/glossaries) for the list of languages available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import deepl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders\n",
    "input_folder = \"../output/tsv/\"\n",
    "output_folder = \"../output/deepl/\"\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(df, target_lang, deepl_auth_key):\n",
    "    # DeepL Preparation\n",
    "    translator = deepl.Translator(deepl_auth_key)\n",
    "    df[target_lang] = translator.translate_text(\n",
    "        df['text'], target_lang=target_lang, split_sentences=0\n",
    "        ) #split_sentences = 0 -> no splitting at all, whole input is treated as one sentence\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salma_hayek_short_merged_ja.csv already translated, skipping...\n"
     ]
    }
   ],
   "source": [
    "# Iterate transcripts (csv files) in the input folder and read them into a dataframe\n",
    "# Translate the transcripts and save them as csv files in the output folder\n",
    "\n",
    "target_lang = \"\" # specify target language here (e.g. \"EN\" for English)\n",
    "deepl_auth_key = \"\" # insert your auth key here\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_merged.csv\"):\n",
    "        output_filename = filename.split(\".csv\")[0] + \"_\" + target_lang + \".csv\"\n",
    "        if output_filename in os.listdir(output_folder):\n",
    "            print(output_filename + \" already translated, skipping...\")\n",
    "        else:\n",
    "            print(\"Now translating: \" + filename)\n",
    "\n",
    "            transcripts = pd.read_csv(os.path.join(input_folder, filename), encoding='latin1')\n",
    "            translate_text(transcripts, target_lang, deepl_auth_key) # source language is automatically detected\n",
    "\n",
    "            output_file = os.path.join(output_folder, output_filename) \n",
    "            transcripts.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
